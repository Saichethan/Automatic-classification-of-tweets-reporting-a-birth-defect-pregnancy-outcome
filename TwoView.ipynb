{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from preprocess import load_data\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxlen = 75\n",
    "hashlen = 3\n",
    "emb_dim = 300\n",
    "\n",
    "print(\"Loading data.....\")\n",
    "\n",
    "vocab_size, train_tweet, train_hash, train_labels, val_tweet, val_hash, val_labels, test_tweet, test_hash, test_labels, word_matrix, val_tweetId, val_userId, val_original_tweet  = load_data()\n",
    "print(\"Data Loading Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweet = Input(shape = (75,),name=\"tweet\")\n",
    "tweet_embeddings = Embedding(input_dim=vocab_size, output_dim=emb_dim, weights=[word_matrix], input_length=maxlen, name=\"Glove\")(tweet)\n",
    "\n",
    "hashtag = Input(shape = (3,),name=\"hashtag\")\n",
    "hash_embeddings = Embedding(input_dim=vocab_size, output_dim=emb_dim, weights=[word_matrix], input_length=3, name=\"Glove_\")(hashtag)#hashlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view tweet\n",
    "conv = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(tweet_embeddings)\n",
    "pool = MaxPooling1D(pool_size=2, padding='same')(conv)\n",
    "lstm = Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.1))(pool)\n",
    "drop = Dropout(0.2)(lstm)\n",
    "dense1 = Dense(200)(drop)\n",
    "f1 = Dense(3,activation=\"softmax\")(dense1)\n",
    "\n",
    "#view hashtag\n",
    "conv_h = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(hash_embeddings)\n",
    "pool_h = MaxPooling1D(pool_size=2, padding='same')(conv_h)\n",
    "lstm_h = Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.1))(pool_h)\n",
    "drop_h = Dropout(0.2)(lstm_h)\n",
    "dense2 = Dense(50)(drop_h)\n",
    "f2 = Dense(3,activation=\"softmax\")(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = concatenate([dense1, dense2])\n",
    "\n",
    "output = Dense(3,activation=\"softmax\")(dense)\n",
    "\n",
    "model = Model(inputs=[tweet, hashtag], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file=\"saves/SingleView.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"SingleView.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath=path, monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "history = model.fit([train_tweet, train_hash], train_labels,\n",
    "                    batch_size=250,\n",
    "                    epochs=10)\n",
    "                    #,\n",
    "                    #callbacks=callbacks_list)\n",
    "                    #,\n",
    "                    #validation_data=([val_tweet, val_hash], val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###predictions###\n",
    "#model.load_weights(path)\n",
    "probability = model.predict([val_tweet, val_hash])\n",
    "predictions = np.argmax(probability,axis=1)\n",
    "predictionsa = predictions + 1\n",
    "\n",
    "#val_tweetId, val_userId, val_original_tweet\n",
    "\n",
    "\n",
    "with open('L1/res/prediction_task5.tsv', 'w+', newline='') as f_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow([\"tweet_id\", \"user_id\", \"tweet\", \"Class\"])\n",
    "    for i in range(len(predictions)):\n",
    "        data = []\n",
    "        data.append(val_tweetId[i])\n",
    "        data.append(val_userId[i])\n",
    "        data.append(val_original_tweet[i])\n",
    "        data.append(predictionsa[i])\n",
    "        tsv_output.writerow(data)\n",
    "\n",
    "f_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['defect', 'possible defect', 'no defect']\n",
    "\n",
    "print(classification_report(val_labels, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
